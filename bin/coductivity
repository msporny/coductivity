#!/usr/bin/env python
"""
Coductivity takes one or more git repositories as input and produces a number
of graphs showing code productivity over time for a group as well as per-person
productivity over time. WARNING: This tool should never be used by itself to
determine whether or not a company or individual is being productive - code
output is just one small measure of a person's influence on the whole health
of a project.
"""
import re
import os
import os.path
import subprocess
import shutil
import sqlite3
import sys
import tempfile
import time
import datetime
from StringIO import StringIO
from optparse import OptionParser
from dulwich.objects import Commit, Tree
from dulwich.repo import Repo
from dulwich.patch import write_tree_diff

USAGE = """%prog GIT_REPOSITORY GIT_REPOSITORY ...

%prog Performs code productivity analysis on the given GIT repository.

************** %prog command line options **************
"""

def _get_options():
    """
    Get options from command line and return them.
    """

    parser = OptionParser(usage=USAGE)
    parser.add_option(
        "--cache-dir", action="store", default="/tmp/coductivity-cache",
        help="The cache directory that will contain all git repositories "
        "being analyzed. [Default: %default]")
    parser.add_option(
        "-c", "--cache-only", action="store_true", default=False,
        help="Do not process any repositories and work directly from the " 
        "cache. [Default: %default]")
    parser.add_option(
        "-l", "--language", action="append", default=
        ["c", "h", "i", "cpp", "js", "html", "css", "tpl", "in", "ac", "py", 
        "java", "php", "inc"],
        help="Add the language in the list of languages to summarize. "
        "This option may be used multiple times - for example, "
        "-l cpp -l h -l py [Default: %default]")
    parser.add_option(
        "-o", "--out_dir", action="store", default=None,
        help="If specified, creates a web-publishable directory containing "
        "the result of the coductivity run. [Default: %default]")
    parser.add_option(
        "-a", "--author-map", action="store", default=None,
        help="A colon-separated map of alias accounts to real accounts. "
        "The map can be used to assign multiple e-mail accounts to one account." 
        " [Default: %default]")
    options, args = parser.parse_args()
    options.args = args

    options.complexity = {"c": 1.0, "h": 0.8, "i": 1.2, "cpp": 1.0, 
       "js": 0.8, "html": 0.6, "css": 1.0, "tpl": 0.7, "in": 1.2, "ac": 1.2, 
       "py": 0.8, "java": 0.9, "php": 0.8, "inc": 0.8, "config": 0.3,
       "json": 0.3}
    #options.complexity = {"c": 1.0, "h": 1.0, "i": 1.0, "cpp": 1.0, 
    #   "js": 1.0, "html": 1.0, "tpl": 1.0, "css": 1.0, "in": 1.0, "ac": 1.0, 
    #   "py": 1.0, "java": 1.0, "php": 1.0, "inc": 1.0}

    return options

def getAuthorMap(options):
    """
    Uses the options.author_map variable to read a file with author mappings
    in it and use those to combine commits made by a single author with 
    multiple e-mail accounts to a single e-mail account.
    """
    rval = {}

    if(options.author_map and os.path.exists(options.author_map)):
        authorFile = open(options.author_map, "r")
        for line in authorFile:
            (alias, email) = line.strip().split(":")
            rval[alias.strip()] = email.strip()

    return rval

def getNames(cache, author_map):
    """
    Gets a list of all names that are in the database.
    """
    rval = []
    c = cache.cursor()
    c.execute("SELECT DISTINCT author FROM commits")

    for row in c:
        rval.append(row[0])

    # Remove the names that have mappings in the author map
    for k, v in author_map.items():
        if(k in rval):
            rval.remove(k)

    return rval

def calculateOverallContributions(author, author_map, cache, options):
    """
    Calculates the overall contributions made by the given committer and 
    generates a string that is easy to read.
    """
    rval = ""
    languages = {}
    aliases = [author]

    # Get all of the aliases for this author
    for k, v in author_map.items():
        if(v == author):
            aliases.append(v)

    # process all of the commits, adding up the code line modification totals
    # Get (language, changes) tuples from database for particular author
    c = cache.cursor()
    qlist = "(" + ",".join(["?" for x in range(0, len(aliases))]) + ")"
    c.execute('SELECT type, changes FROM commits WHERE author IN ' + qlist, 
        aliases)

    # Add the changes to the languages list
    for row in c:
        languages[row[0]] = languages.get(row[0], 0) + row[1]

    rval = "Contributor: %s\n" % (author,)

    # determine if the language list should be filtered down
    lkeys = languages.keys()
    if(len(options.language) > 0):
        lkeys = options.language

    # gather all of the languages that have been marked as being important
    total = 0
    for k in lkeys:
        if(k in languages.keys()):
            esloc = languages[k] * options.complexity[k]
            rval += "    %s: %i (effort), %i (SLOC)\n" % \
                (k, esloc, languages[k])
            total += esloc
    rval += "    Total: %i (effort)\n" % (total,)

    return rval

def calculateDiff(repo, revision, commit, lastCommit):
    """
    Calculates a diff between two revisions in a git revision history and 
    records the value in the given 'commit' object.
    """
    diff = StringIO()

    # Generate the diff
    write_tree_diff(diff, repo.object_store, lastCommit.tree, revision.tree)
    diff.seek(0)
    
    # Keep track of the active file type and whether or not
    # changes should be ignored
    activeFileType = None
    ignoreFile = False
    ignoreLine = False
    
    # This loop does several things - it attempts to identify the
    # file type by the extension, counts file modifications,
    # and ignores files that are deleted. These stats are captured
    # in a commit object and added to the author dictionary
    whitespaceStringRe = re.compile("\s")
    for line in diff:
        # determine the active file type and whether or not the
        # line should be ignored
        if(line.startswith("--- ")):
            ignoreLine = True
            if(line.startswith("--- /dev/null")):
                activeFileType = None
            else:
                activeFileType = line.split(".")[-1].strip()
                if(activeFileType.startswith("---")):
                    print "WARNING: Ignoring unknown file type %s" % \
                        (activeFileType,)
                    activeFileType = None
                    ignoreFile = True
            ignoreFile = False
        elif(line.startswith("+++ ")):
            ignoreLine = True
            if(line.startswith("+++ /dev/null")):
                # don't count file deletions as modified lines
                ignoreFile = True
            elif(not activeFileType):
                activeFileType = line.split(".")[-1].strip()
                if(activeFileType.startswith("---")):
                    print "WARNING: Ignoring unknown file type %s" % \
                        (activeFileType,)
                    activeFileType = None
                    ignoreFile = True

        # Ignore lines that are just whitespace or parenthesis
        cleanedLine = re.sub(whitespaceStringRe, "", line)
        if(ignoreLine == False and len(cleanedLine) < 4):
            ignoreLine = True

        # Record the modification if there is an active file type
        # and the line should not be ignored, and the line starts
        # with a '+' or a '-'
        if(activeFileType and not ignoreFile and not ignoreLine and 
            (line.startswith("-") or line.startswith("+"))):
            #print "    Counting:", line.strip()[:60]
            commit[activeFileType] = commit.get(activeFileType, 0) + 1
            commit["totalChanges"] = commit.get("totalChanges", 0) + 1
        else:
            #print "___IGNOR:", line.strip()
            ignoreLine = False

def getTimestamp(dt):
    """
    Converts a Python datetime object into a POSIX-compatible 1970-based epoch 
    timestamp.
    """
    return int(time.mktime(dt.timetuple()))

def getCommitTotals(c, startDate, endDate, author = None):
    rval = {}
    
    # Calculate the date changes
    oneDay = datetime.timedelta(1)
    currentDate = startDate
    currentMonth = startDate.month
    changes = 0
    while(currentDate < endDate):
        nextDate = currentDate + oneDay
        if(author == None):
            c.execute("SELECT SUM(changes) FROM commits "
                "WHERE time >= ? AND time < ?", 
                (getTimestamp(currentDate), getTimestamp(nextDate)))
        else:
            c.execute("SELECT SUM(changes) FROM commits "
                "WHERE time >= ? AND time < ? AND author = ?", 
                (getTimestamp(currentDate), getTimestamp(nextDate), author))

        # update the dated commit totals
        for row in c:
            if(row[0] != None):
                changes += row[0]
            rval[currentDate] = changes

        currentDate += oneDay

        # Reset the change counter at the beginning of the month
        if(currentDate.month != currentMonth):
            changes = 0
            currentMonth = currentDate.month

    return rval

def generateJavaScriptData(cache, options):
    """
    Generates a set of Protovis JavaScript code that can be used to visualize
    overall developer throughput.
    """
    rval = ""
    startDate = 0
    endDate = 0
    commitTotals = {}

    # Get the minimum and maximum date in the database
    c = cache.cursor()
    c.execute("SELECT MIN(time), MAX(time) FROM commits")
    minmaxdates = c.fetchone()
    startDate = datetime.date.fromtimestamp(minmaxdates[0])
    endDate = datetime.date.fromtimestamp(minmaxdates[1])

    # Get all of the names to 
    commitTotals["all"] = getCommitTotals(c, startDate, endDate)
    
    names = getNames(cache, author_map)
    for n in names:
        formattedName = \
            n.split("<")[0].strip().lower().replace(" ", "_").replace(".", "")
        commitTotals[formattedName] = getCommitTotals(c, startDate, endDate, n)

    # Generate the JavaScript data file contents
    rval = "var start = new Date(%s);\n" % (getTimestamp(startDate) * 1000,)
    rval += "var data = {\n"

    # Output key/value pair data for every committer
    for n in commitTotals.keys():
        rval += "   \"%s\": [\n" % (n,)
        currentDate = startDate
        oneDay = datetime.timedelta(1)
        # Output the list of commits by the committer
        while(currentDate < endDate):
            rval += "      {x: %s, y: %s},\n" % \
                (getTimestamp(currentDate) * 1000, commitTotals[n][currentDate])
            currentDate += oneDay
        rval += "   ],\n"
    rval += "};\n"
    rval += "var end = new Date(%s);\n" % (getTimestamp(endDate) * 1000,)

    return rval;

def setupCache(options):
    """
    Ensures that the cache directory exists and that the cache database exists.
    Returns an open connection to the database cache. Make sure to close the 
    connection when you are done with it.
    """
    if(not os.path.isdir(options.cache_dir)):
        os.makedirs(options.cache_dir)

    cacheFile = os.path.join(options.cache_dir, "cache.db")
    if(not os.path.exists(cacheFile)):
        con = sqlite3.connect(cacheFile)
        con.execute("""CREATE TABLE commits (id VARCHAR(42), 
            repository VARCHAR(128), time DATETIME, author VARCHAR(128),
            type VARCHAR(6), changes INTEGER)""")
        con.execute("""CREATE UNIQUE INDEX commit_index ON commits 
            (id, time, type)""")
        con.execute("""CREATE INDEX authors_index ON commits (author)""")
        con.commit()
        con.close()

    return sqlite3.connect(cacheFile)

def processRevisions(options, author_map, repo, reponame, history, cache):
    # process all of the commits reachable via git HEAD
    lastCommit = None
    for revision in history:
        # map the aliases for the author correctly
        author = revision.author
        if(author_map.has_key(author)):
            author = author_map[author]
        
        # create the new commit tracking object
        commit = {"author": author}
        commit["time"] = revision.commit_time
        commit["totalChanges"] = 0

        # dump a bit of status so that the developer knows that we're
        # workin' it
        commitTime = datetime.date.fromtimestamp(revision.commit_time)

        if(lastCommit):
            calculateDiff(repo, revision, commit, lastCommit)
            # Do not add a commit that has more than 1000 total changes because
            # it is most likely just a global search/replace for text
            if(commit["totalChanges"] < 750):
                # Add the commit to the cache
                lkeys = commit.keys()
                lkeys.remove("author")
                lkeys.remove("time")
                lkeys.remove("totalChanges")
                for l in lkeys:
                    try:
                        changes = commit[l]
                        cache.execute("""INSERT INTO commits 
                            (id, repository, time, author, type, changes) 
                            VALUES (?, ?, ?, ?, ?, ?)""", 
                            (revision.id, reponame, commit["time"], 
                            commit["author"], l, changes))
                        print reponame, commitTime, commit["author"], changes, revision.id
                        cache.commit()
                    except sqlite3.IntegrityError:
                        return
                    except sqlite3.ProgrammingError:
                        print "ERROR: INSERT INTO commits " + \
                            "(id, repository, time, author, type, changes) " + \
                            "VALUES (%s, %s, %s, %s, %s, %s)" % \
                            (revision.id, reponame, commit["time"],
                            commit["author"], l, changes)
                        return
            else:
                print "WARNING: Ignoring bulk edit on ", reponame, commit["author"], commit["totalChanges"]

        lastCommit = revision

def main():
    """
    The main entry point for the script.
    """
    options = _get_options()

    # Check to make sure at least the project directory was specified
    if(len(options.args) < 1 and not options.cache_only):
        print "ERROR: You must specify at least one project directory " + \
            "or specify --cache-only."
        sys.exit(1)

    author_map = getAuthorMap(options)

    # Create the coductivity cache directory and setup the cache database
    cache = setupCache(options)

    # Assume each command-line parameter that is not an option is a path to
    # a git repository
    for repository in options.args:
        reponame = repository.split("/")[-1]
        repo = Repo(repository)
        history = repo.revision_history(repo.head())
        processRevisions(options, author_map, repo, reponame, history, cache)

    if(not options.out_dir):
        # if there isn't an output directory, dump some summary info to stdout
        names = getNames(cache, author_map)
        names.sort()

        for n in names:
            print calculateOverallContributions(n, author_map, cache, options)
    else:
        # if an output directory exists, generate a web page
        dataJavaScript = generateJavaScriptData(cache, options)
        dataFilename = os.path.join(options.out_dir, "data.js")
        
        # Create the web directory
        if(not os.path.exists(options.out_dir)):
            os.makedirs(options.out_dir)
        
        # Copy all of the helper files over
        files = ["coductivity.css", "coductivity.js", "index.html", 
            "protovis-r3.2.js"]

        for f in files:
            shutil.copyfile(os.path.join("web", f),
                os.path.join(options.out_dir, f))

        data = open(dataFilename, "w")
        data.write(dataJavaScript)
        data.close()

if __name__ == "__main__":
    main()

